{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:07:31.005473Z",
     "start_time": "2024-03-14T14:07:31.002334Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.analysis_from_interaction import *\n",
    "from egg.core.language_analysis import Disent\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "from utils.analysis_tools_lazimpa import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate metrics from stored interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T14:07:35.486572Z",
     "start_time": "2024-03-14T14:07:35.482298Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', '(3,8)', '(4,4)')\n",
    "n_attributes = (3, 3, 4)\n",
    "n_values = (4, 8, 4)\n",
    "n_epochs = 300\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3/' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lazimpa_context_aware'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_unaware = False # whether original or context_unaware simulations are evaluated\n",
    "lazy = True # whether the lazy agent is used\n",
    "impatient = True\n",
    "setting = \"\"\n",
    "pickle_data = True\n",
    "if not lazy:\n",
    "    start = 'impatience_' if impatient else ''\n",
    "    if context_unaware:\n",
    "        setting = start + 'context_unaware'\n",
    "    else:\n",
    "        setting = start + 'context_aware'\n",
    "        if impatient == False:\n",
    "            setting = 'standard'\n",
    "else:\n",
    "    start = 'lazimpa' if impatient else 'lazy'\n",
    "    if context_unaware:\n",
    "        setting = start + '_context_unaware'\n",
    "    else:\n",
    "        setting = start + '_context_aware'\n",
    "setting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy scores: MI, effectiveness, efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T14:06:37.646673Z",
     "start_time": "2024-03-06T14:06:33.540807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:315: RuntimeWarning: invalid value encountered in divide\n",
      "  (m_entropy_concept_x_context + c_entropy_concept_x_context - joint_entropy_concept_x_context)\n",
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:324: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_effectiveness_conc_x_cont = ((joint_entropy_concept_x_context - m_entropy_concept_x_context)\n",
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:331: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_consistency_conc_x_cont = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'normalized_mutual_info': 0.5646424659616172,\n",
       " 'normalized_mutual_info_hierarchical': array([0.9412313 , 0.71581218, 0.61050991, 0.56984363]),\n",
       " 'normalized_mutual_info_context_dep': array([0.60728343, 0.64302973, 0.69433659, 0.73332883]),\n",
       " 'normalized_mutual_info_concept_x_context': array([0.9412313 ,        nan,        nan,        nan, 0.73845603,\n",
       "        0.75726969,        nan,        nan, 0.64400332, 0.67973626,\n",
       "        0.72967362,        nan, 0.62280925, 0.65584262, 0.70397423,\n",
       "        0.73332883]),\n",
       " 'effectiveness': 0.5327886972087245,\n",
       " 'effectiveness_hierarchical': array([0.95796588, 0.7092366 , 0.60438355, 0.58895723]),\n",
       " 'effectiveness_context_dep': array([0.52052878, 0.58264702, 0.68003261, 0.7767193 ]),\n",
       " 'effectiveness_concept_x_context': array([0.95796588,        nan,        nan,        nan, 0.69333176,\n",
       "        0.75908013,        nan,        nan, 0.58151209, 0.65248153,\n",
       "        0.74343608,        nan, 0.57371813, 0.62992165, 0.72519545,\n",
       "        0.7767193 ]),\n",
       " 'consistency': 0.6005473101182175,\n",
       " 'consistency_hierarchical': array([0.92507135, 0.72251083, 0.61676173, 0.55193163]),\n",
       " 'consistency_context_dep': array([0.72873988, 0.71737498, 0.70925525, 0.69452978]),\n",
       " 'consistency_concept_x_context': array([0.92507135,        nan,        nan,        nan, 0.78986285,\n",
       "        0.75546787,        nan,        nan, 0.72154269, 0.70936714,\n",
       "        0.71641144,        nan, 0.68108762, 0.68398841, 0.68395968,\n",
       "        0.69452978])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = information_scores(interaction, attributes, values, normalizer=\"arithmetic\")\n",
    "\n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'entropy_scores.pkl', 'wb'))\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T16:14:53.162856Z",
     "start_time": "2024-02-28T16:14:51.541390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 2, 1])\n",
      "hierarchical [1.402, 1.076, 1.122]\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 1, 0])\n",
      "hierarchical [1.465, 1.296, 1.183]\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([0, 1, 1,  ..., 1, 1, 2])\n",
      "hierarchical [1.042, 1.08, 1.085]\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 2, 1,  ..., 1, 0, 1])\n",
      "hierarchical [1.036, 1.077, 1.03]\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "hierarchical [1.441, 1.197, 1.203]\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 2, 2,  ..., 2, 2, 2])\n",
      "hierarchical [1.8, 1.542, 1.467]\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([2, 0, 2,  ..., 2, 2, 1])\n",
      "hierarchical [1.741, 1.285, 1.376]\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([2, 1, 2,  ..., 2, 2, 2])\n",
      "hierarchical [1.88, 1.709, 1.681]\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 0, 1,  ..., 1, 2, 1])\n",
      "hierarchical [2.261, 1.724, 1.414]\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 1, 2])\n",
      "hierarchical [1.584, 1.344, 1.338]\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([0, 0, 0,  ..., 1, 1, 1])\n",
      "hierarchical [0.808, 0.988, 1.055, 1.083]\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 2,  ..., 2, 2, 2])\n",
      "hierarchical [1.084, 1.142, 1.084, 1.078]\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([0, 1, 1,  ..., 2, 2, 1])\n",
      "hierarchical [1.01, 1.134, 1.169, 1.215]\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 1, 0])\n",
      "hierarchical [1.022, 1.017, 1.062, 1.095]\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "message length tensor([1, 1, 1,  ..., 1, 1, 2])\n",
      "hierarchical [0.895, 1.011, 1.046, 1.065]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.895, 1.011, 1.046, 1.065]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we evaluated message length per hierarchy level after training but \n",
    "# you can also use the HierarchicalMessageLength callback and store the results \n",
    "# TODO: Message length results look weird, needs to be fixed!\n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    for run in range(5):\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = message_length_per_hierarchy_level(interaction, attributes)\n",
    "        \n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'message_length_hierarchical.pkl', 'wb'))\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  symbol redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T16:14:57.892753Z",
     "start_time": "2024-02-28T16:14:53.164028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\emergent-abstractions\\utils\\analysis_from_interaction.py:446: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    attributes = n_attributes[d]\n",
    "    values = n_values[d]\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    for run in range(5):\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        #symbol_f = np.load(path_to_run + 'symbols_pernsame.npy')\n",
    "        interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "        redundancy, MI = symbol_frequency(interaction, attributes, values, vocab_size)\n",
    "        \n",
    "        scores = {'symbol_redundancy': redundancy, 'MI_symbol-attribute_value': MI}\n",
    "        \n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'symbol_redundancy.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZLA significance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_message_length': 2.038888931274414,\n",
       " 'mean_weighted_message_length': 1.0512007474899292,\n",
       " 'p_zla': 0.0,\n",
       " 'min_bool_value': 0,\n",
       " 'max_bool_value': 0,\n",
       " 'message_length_context_dep': [0.946, 0.994, 1.128, 1.286],\n",
       " 'message_length_context_x_concept': [[nan, 0.895, 0.945, 0.948, 0.948],\n",
       "  [nan, nan, 1.076, 0.988, 0.971],\n",
       "  [nan, nan, nan, 1.206, 1.054],\n",
       "  [nan, nan, nan, nan, 1.286]],\n",
       " 'message_length_frequency': ([0, 1, 2, 3, 4],\n",
       "  tensor([1699, 8008, 2258,   26,    1]))}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "\n",
    "        scores = ZLA_significance_score(interaction,values=n_values[d],num_permutations=100000, remove_after_eos=True)\n",
    "\n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'ZLA_significance.pkl', 'wb'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_message_length': 4.0,\n",
       " 'mean_weighted_message_length': 4.0,\n",
       " 'p_zla': 1.0,\n",
       " 'min_bool_value': 1,\n",
       " 'max_bool_value': 1,\n",
       " 'message_length_context_dep': [4.0, 4.0, 4.0, 4.0],\n",
       " 'message_length_context_x_concept': [[nan, 4.0, 4.0, 4.0, 4.0],\n",
       "  [nan, nan, 4.0, 4.0, 4.0],\n",
       "  [nan, nan, nan, 4.0, 4.0],\n",
       "  [nan, nan, nan, nan, 4.0]],\n",
       " 'message_length_frequency': ([0, 1, 2, 3, 4],\n",
       "  tensor([    0,     0,     0,     0, 12082]))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard agent\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str('standard') +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],\"standard\",run,n_epochs)\n",
    "\n",
    "        scores = ZLA_significance_score(interaction,values=n_values[d],num_permutations=100000,remove_after_eos=True)\n",
    "\n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'ZLA_significance.pkl', 'wb'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbol Informativeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "\n",
      " Max (normal) switch:  {'positional_encoding': [0.9615134000778198, 0.9628770351409912, 1.0], 'effective_length': 1.077185034751892, 'information_density': 0.9619868397712708}\n",
      "\n",
      "Unimportant switch:  {'positional_encoding': tensor([0.0496, 0.0093, 0.0000]), 'effective_length': tensor(0.0454), 'information_density': tensor(0.0405)}\n",
      "Number of important symbols:  tensor(80)\n"
     ]
    }
   ],
   "source": [
    "# Test if change of two unimportant values, without changing the actual symbol has an effect\n",
    "interaction = load_interaction(paths[0],setting,0,n_epochs)\n",
    "attributes = n_attributes[0]\n",
    "values = n_values[0]\n",
    "listener,_,_ = load_listener(paths[0],setting,0,attributes, values,context_unaware)\n",
    "eos_token = 0.0\n",
    "\n",
    "# symbol informativeness\n",
    "messages = interaction.message\n",
    "num_messages, message_length, vocab_size = messages.shape\n",
    "\n",
    "# values to be switched\n",
    "max_values, original_messages = messages.max(dim=-1)\n",
    "\n",
    "eos_mask_total = eos_token != original_messages\n",
    "\n",
    "# only values before eos, to switch\n",
    "eos_excluded_cumulative = torch.cat([ eos_mask_total[:,:i+1].sum(dim=1).unsqueeze(1) == i+1 for i in range(message_length) ],dim=1)\n",
    "\n",
    "# until eos, evaluating changes\n",
    "eos_included_cumualtive = torch.cat([torch.ones_like(eos_excluded_cumulative[:,-1]).unsqueeze(1).bool(), eos_excluded_cumulative[:,:-1]],dim=1)\n",
    "\n",
    "# Prediction for original messages, exclude prediction for values after eos\n",
    "prediction = (listener(messages,interaction.receiver_input) > 0).float()\n",
    "empty_prediction = torch.zeros_like(prediction)\n",
    "prediction = torch.where(eos_included_cumualtive.unsqueeze(-1),prediction,empty_prediction)\n",
    "\n",
    "Lambda_m_k_list = []\n",
    "\n",
    "for i in range(message_length-1): # index = -1 is always eos and not changed. \n",
    "\n",
    "    # pick random new symbol index to switch with\n",
    "    switch_index = torch.randint(1,vocab_size,(num_messages,))\n",
    "\n",
    "    # make sure switch_index != original_messages\n",
    "    same_indices = (switch_index == original_messages[:,i])\n",
    "    while same_indices.any():\n",
    "        switch_index[same_indices] = torch.randint(1, vocab_size, (same_indices.sum().item(),))\n",
    "        same_indices = (switch_index == original_messages[:,i])\n",
    "\n",
    "    # values to switch with\n",
    "    new_value = torch.gather(messages[:,i,:],-1,switch_index.unsqueeze(-1)).squeeze()\n",
    "\n",
    "    # pick random new symbol index to switch with #2 for switching in background\n",
    "    switch_index2 = torch.randint(1,vocab_size,(num_messages,))\n",
    "\n",
    "    # make sure switch_index != original_messages and != switch_index\n",
    "    same_indices = (switch_index2 == original_messages[:,i]) + (switch_index2 == switch_index)\n",
    "    while same_indices.any():\n",
    "        switch_index2[same_indices] = torch.randint(1, vocab_size, (same_indices.sum().item(),))\n",
    "        same_indices = (switch_index2 == original_messages[:,i]) + (switch_index2 == switch_index)\n",
    "\n",
    "    # values to switch with\n",
    "    new_value2 = torch.gather(messages[:,i,:],-1,switch_index2.unsqueeze(-1)).squeeze()\n",
    "\n",
    "    messages_manipulated = messages.clone()\n",
    "\n",
    "    # if eosed, take old value in so no switch (with 2 not max)\n",
    "    new_value_without_eos = torch.where(eos_excluded_cumulative[:,i].squeeze(), new_value,new_value2)\n",
    "    new_value2_without_eos = torch.where(eos_excluded_cumulative[:,i].squeeze(), new_value2,new_value)\n",
    "\n",
    "    # switch value i of all messages to new symbol # not max\n",
    "    messages_manipulated[:,i].scatter_(-1,switch_index2.unsqueeze(-1),new_value_without_eos.unsqueeze(-1))\n",
    "    messages_manipulated[:,i].scatter_(-1,switch_index.unsqueeze(-1),new_value2_without_eos.unsqueeze(-1))\n",
    "\n",
    "    prediction_manipulated = (listener(messages_manipulated,interaction.receiver_input) > 0).float() # bigger 0 means thinks its a concept object\n",
    "    prediction_manipulated = torch.where(eos_included_cumualtive.unsqueeze(-1),prediction_manipulated,empty_prediction)\n",
    "\n",
    "    # compare whether same classification not same values\n",
    "    # only include predictions for symbols that are not eosed yet.\n",
    "    Lambda_m_k_position = (prediction != prediction_manipulated).sum(dim=(1,2)).unsqueeze(1).bool() # (num_messages, 1 )\n",
    "    Lambda_m_k_list.append(Lambda_m_k_position)\n",
    "\n",
    "Lambda_m_k = torch.cat(Lambda_m_k_list,dim=1)\n",
    "eos_mask = eos_excluded_cumulative[:,:-1] # both should be the same shape\n",
    "\n",
    "scores = information_analysis(listener,interaction,eos_token=0.0)\n",
    "print(\"\\n Max (normal) switch: \", scores)\n",
    "\n",
    "return_dict = {\n",
    "    \"positional_encoding\" : positional_encoding(Lambda_m_k, eos_mask),\n",
    "    \"effective_length\" : effective_length(Lambda_m_k, eos_mask),\n",
    "    \"information_density\" : information_density(Lambda_m_k,eos_mask)\n",
    "}\n",
    "print(\"\\nUnimportant switch: \", return_dict)\n",
    "print(\"Number of important symbols: \", Lambda_m_k.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'positional_encoding': [0.9131448268890381,\n",
       "  0.9326039552688599,\n",
       "  0.8888888955116272,\n",
       "  1.0],\n",
       " 'effective_length': 0.9635590314865112,\n",
       " 'information_density': 0.9166269898414612}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal symbol information analysis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "\n",
    "        listener,_,_ = load_listener(paths[d],setting,run,attributes, values,context_unaware)\n",
    "\n",
    "        scores = information_analysis(listener,interaction,eos_token=0.0)\n",
    "\n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'symbol_informativeness.pkl', 'wb'))\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,4)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(3,8)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/0/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/1/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/2/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/3/interactions/train/epoch_300/interaction_gpu0\n",
      "results/(4,4)_game_size_10_vsf_3//standard/4/interactions/train/epoch_300/interaction_gpu0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'positional_encoding': [0.9983446598052979,\n",
       "  0.9723555445671082,\n",
       "  0.8611156940460205,\n",
       "  0.7522761225700378],\n",
       " 'effective_length': 3.584092140197754,\n",
       " 'information_density': 0.8960230350494385}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal symbol information analysis for standard agent (control)\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + \"standard\" +'/' + str(run) + '/' \n",
    "        interaction = load_interaction(paths[d],\"standard\",run,n_epochs)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "\n",
    "        listener,_,_ = load_listener(paths[d],\"standard\",run,attributes, values,False)\n",
    "\n",
    "        scores = information_analysis(listener,interaction,eos_token=0.0)\n",
    "\n",
    "        if pickle_data:\n",
    "            pickle.dump(scores, open(path_to_run + 'symbol_informativeness.pkl', 'wb'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_3//lazimpa_context_aware/4/interactions/train/epoch_300/interaction_gpu0\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000])\n",
      "tensor([1.7881e-05, 1.1921e-06, 0.0000e+00,  ..., 8.3447e-07, 2.2888e-04,\n",
      "        1.9958e-03])\n",
      "tensor([1.7878e-05, 1.1911e-06, 0.0000e+00,  ..., 6.4132e-07, 2.2738e-04,\n",
      "        1.9958e-03])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.0000, 2.0000,  ..., 2.0000, 2.0005, 2.0040])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for debugging only, calculate probability mass\n",
    "interaction = load_interaction(paths[d],setting,run,n_epochs)\n",
    "listener,_,_ = load_listener(paths[d],setting,run,attributes, values,context_unaware)\n",
    "message = interaction.message\n",
    "receiver_output = listener(message,interaction.receiver_input)\n",
    "\n",
    "impatience = True\n",
    "\n",
    "not_eosed_before = torch.ones(receiver_output.size(0))\n",
    "expected_length = 0.0 # final includes eos here\n",
    "z = 0.0\n",
    "\n",
    "for step in range(receiver_output.size(1)):\n",
    "    eos_mask = message[:, step, 0]  # always eos == 0\n",
    "    if impatience:\n",
    "        add_mask = not_eosed_before\n",
    "    else:\n",
    "        add_mask = eos_mask * not_eosed_before\n",
    "    z += add_mask\n",
    "    expected_length += add_mask.detach() * (1.0 + step)\n",
    "    print(not_eosed_before)\n",
    "    not_eosed_before = not_eosed_before * (1.0 - eos_mask)\n",
    "\n",
    "expected_length += (step + 1) * not_eosed_before\n",
    "z += not_eosed_before\n",
    "assert z.allclose(\n",
    "            z\n",
    "        ), f\"lost probability mass, {z.min()}, {z.max()}\"\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis for attribute visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  compositionality scores: topsim, posdis, bosdis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### topsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T18:20:39.525914Z",
     "start_time": "2024-03-06T14:09:08.937473Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.18796677386952407, 'topsim_specific_train': 0.22305092596961135, 'topsim_generic_train': 0.3070700850045201, 'topsim_val': 0.2242431716732342, 'topsim_specific_val': 0.27226513675041514, 'topsim_generic_val': 0.3135998635217133}\n",
      "dataset (3,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.19731779138649497, 'topsim_specific_train': 0.20511581489576586, 'topsim_generic_train': 0.38178840983386914, 'topsim_val': 0.23233058627732506, 'topsim_specific_val': 0.2619156159893861, 'topsim_generic_val': 0.2865912960301693}\n",
      "dataset (3,4) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2377904370201794, 'topsim_specific_train': 0.23453927759987075, 'topsim_generic_train': 0.3289677946979688, 'topsim_val': 0.25799971965965923, 'topsim_specific_val': 0.2647576115695098, 'topsim_generic_val': 0.1538921964646194}\n",
      "dataset (3,4) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.17464296431309767, 'topsim_specific_train': 0.18883721859686134, 'topsim_generic_train': 0.26879750639425487, 'topsim_val': 0.2529031028693822, 'topsim_specific_val': 0.2491444499601285, 'topsim_generic_val': 0.3341198730145754}\n",
      "dataset (3,4) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.17442194163121866, 'topsim_specific_train': 0.1638722663276361, 'topsim_generic_train': 0.6047689500252655, 'topsim_val': 0.21451656516607756, 'topsim_specific_val': 0.18750319635139684, 'topsim_generic_val': 0.38136687953570425}\n",
      "dataset (3,8) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.09408622486415565, 'topsim_specific_train': 0.10205978547362501, 'topsim_generic_train': 0.3814775375551397, 'topsim_val': 0.11009925865924244, 'topsim_specific_val': 0.11696775430890656, 'topsim_generic_val': 0.3197844315184598}\n",
      "dataset (3,8) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.09927758771554963, 'topsim_specific_train': 0.10520717669293123, 'topsim_generic_train': 0.17225845701412054, 'topsim_val': 0.13206226084031988, 'topsim_specific_val': 0.12166812756396624, 'topsim_generic_val': 0.16895025455367335}\n",
      "dataset (3,8) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.09627178759894484, 'topsim_specific_train': 0.09789994471882488, 'topsim_generic_train': 0.2352529452960632, 'topsim_val': 0.09655873140714107, 'topsim_specific_val': 0.10284938575744229, 'topsim_generic_val': 0.2092267094737035}\n",
      "dataset (3,8) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.0856889648752605, 'topsim_specific_train': 0.11835502599066382, 'topsim_generic_train': 0.29044127731786556, 'topsim_val': 0.08662683102584813, 'topsim_specific_val': 0.11677176649801926, 'topsim_generic_val': 0.2267071492635142}\n",
      "dataset (3,8) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.0945345352121572, 'topsim_specific_train': 0.10564307413519858, 'topsim_generic_train': 0.4020218979344178, 'topsim_val': 0.11098637734597117, 'topsim_specific_val': 0.11678524284435551, 'topsim_generic_val': 0.2971597129765212}\n",
      "dataset (4,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.14217166043406404, 'topsim_specific_train': 0.12591758368904366, 'topsim_generic_train': 0.33515532751920235, 'topsim_val': 0.2136907653322349, 'topsim_specific_val': 0.20503491205505817, 'topsim_generic_val': 0.3822843195057136}\n",
      "dataset (4,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.15098355825566223, 'topsim_specific_train': 0.14149503268380623, 'topsim_generic_train': 0.3707222392328253, 'topsim_val': 0.2172530746788787, 'topsim_specific_val': 0.23268053843177883, 'topsim_generic_val': 0.2290906546037256}\n",
      "dataset (4,4) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.13099895376420695, 'topsim_specific_train': 0.15715079362792028, 'topsim_generic_train': 0.38760893833285526, 'topsim_val': 0.1967008806073326, 'topsim_specific_val': 0.1926141917845076, 'topsim_generic_val': 0.24388052861386791}\n",
      "dataset (4,4) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.14011612801802698, 'topsim_specific_train': 0.1404961389015337, 'topsim_generic_train': 0.2557179251941211, 'topsim_val': 0.2298565609372789, 'topsim_specific_val': 0.2315631201572879, 'topsim_generic_val': 0.1371129518405933}\n",
      "dataset (4,4) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.1246473307062682, 'topsim_specific_train': 0.09870724807018684, 'topsim_generic_train': 0.3171348483456151, 'topsim_val': 0.16344395061754957, 'topsim_specific_val': 0.15735146213929216, 'topsim_generic_val': 0.2767749858942601}\n"
     ]
    }
   ],
   "source": [
    "# topsim\n",
    "# although topsim values are stored throughout training if callbacks are verbose, we reevaluate the\n",
    "# final topsim scores with more data points \n",
    "\n",
    "samples = 1000 # maybe shuffle from these because otherwise I just take the first 5,000 (which might not be the best)\n",
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    dim = [n_values[d]]*n_attributes[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        topsim_final = {}\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        \n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "                \n",
    "                  \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "            specific_idx = np.where(np.sum(fixed, axis=1)==n_attributes[d])[0]\n",
    "            messages_specific = messages[specific_idx]\n",
    "            concepts_specific = concepts[specific_idx]\n",
    "            \n",
    "            generic_idx = np.where(np.sum(fixed, axis=1)==1)[0]\n",
    "            messages_generic = messages[generic_idx]\n",
    "            concepts_generic = concepts[generic_idx]\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "            messages_specific = [msg.tolist() for msg in messages_specific]\n",
    "            messages_generic = [msg.tolist() for msg in messages_generic]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "            # randomly take samples when more than 5000 samples are available\n",
    "            # if len(encoded_input) > samples: \n",
    "            #     print(\"sampling\")\n",
    "            #     sample_indices = random.sample(range(len(encoded_input)), samples)\n",
    "            #     sampled_input = [encoded_input[i] for i in sample_indices]\n",
    "            #     sampled_messages = [messages[i] for i in sample_indices]\n",
    "            #     print(\"start computing\")\n",
    "            #     print(len(sampled_input), len(sampled_input[0]), len(sampled_input[0][0]))\n",
    "            #     topsim = TOPSIM.compute_topsim(sampled_input, sampled_messages)\n",
    "            # else:\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples]) # default: hausdorff distance for concepts, edit distance for messages\n",
    "            # if len(concepts_specific) > samples:\n",
    "            #     print(\"sampling specific\")\n",
    "            #     sample_indices_specific = random.sample(range(len(concepts_specific)), samples)\n",
    "            #     sampled_input_specific = [concepts_specific[i] for i in sample_indices_specific]\n",
    "            #     sampled_messages_specific = [messages_specific[i] for i in sample_indices_specific]\n",
    "            #     topsim_specific = TOPSIM.compute_topsim(sampled_input_specific, sampled_messages_specific, \n",
    "            #                                             meaning_distance_fn=\"edit\")\n",
    "            # else:\n",
    "            topsim_specific = TOPSIM.compute_topsim(concepts_specific[0:samples], messages_specific[0:samples], \n",
    "                                                        meaning_distance_fn=\"edit\")\n",
    "            \n",
    "            topsim_generic = TOPSIM.compute_topsim(concepts_generic[0:samples], messages_generic[0:samples],\n",
    "                                                   meaning_distance_fn=\"edit\")\n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "            topsim_final['topsim_specific_' + mode] = topsim_specific\n",
    "            topsim_final['topsim_generic_' + mode] = topsim_generic\n",
    "    \n",
    "        if pickle_data:\n",
    "            pickle.dump(topsim_final, open(path_to_run +  \"topsim_final.pkl\", \"wb\" ) )\n",
    "        print(topsim_final)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Topsim over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-14T14:07:47.776462Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "dataset (3,4) run 1\n",
      "dataset (3,4) run 2\n",
      "dataset (3,4) run 3\n",
      "dataset (3,4) run 4\n",
      "dataset (3,8) run 0\n",
      "dataset (3,8) run 1\n",
      "dataset (3,8) run 2\n",
      "dataset (3,8) run 3\n",
      "dataset (3,8) run 4\n",
      "dataset (4,4) run 0\n",
      "dataset (4,4) run 1\n",
      "dataset (4,4) run 2\n",
      "dataset (4,4) run 3\n",
      "dataset (4,4) run 4\n"
     ]
    }
   ],
   "source": [
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "        dim = [n_values[0]] * n_attributes[0]\n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        samples = 1000\n",
    "        num_batches = len(messages) // samples + (len(messages) % samples > 0)\n",
    "        topsim_over_time = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            messages_batch = messages[i * samples:(i + 1) * samples]\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[i * samples:(i + 1) * samples], messages_batch)\n",
    "            topsim_over_time.append(topsim)\n",
    "            \n",
    "        if pickle_data:\n",
    "            pickle.dump(topsim_over_time, open(path_to_run +  \"topsim_over_time.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Posdis and Bosdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-28T16:16:18.597875Z",
     "start_time": "2024-02-28T16:14:57.896059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set [4, 4, 4]\n",
      "{'posdis_specific': 0.04806709662079811, 'bosdis_specific': 0.24908646941184998, 'posdis_generic': 0.07418928295373917, 'bosdis_generic': 0.3077387809753418, 'posdis': 0.04486815631389618, 'bosdis': 0.2588385343551636}\n",
      "{'posdis_specific': 0.05818255618214607, 'bosdis_specific': 0.20112445950508118, 'posdis_generic': 0.10012919455766678, 'bosdis_generic': 0.32522934675216675, 'posdis': 0.03896735981106758, 'bosdis': 0.20639926195144653}\n",
      "{'posdis_specific': 0.05935806408524513, 'bosdis_specific': 0.2289711833000183, 'posdis_generic': 0.04975811019539833, 'bosdis_generic': 0.22203244268894196, 'posdis': 0.040026601403951645, 'bosdis': 0.22377990186214447}\n",
      "{'posdis_specific': 0.06014275923371315, 'bosdis_specific': 0.30911585688591003, 'posdis_generic': 0.19710777699947357, 'bosdis_generic': 0.25875261425971985, 'posdis': 0.0431329719722271, 'bosdis': 0.30128157138824463}\n",
      "{'posdis_specific': 0.06762847304344177, 'bosdis_specific': 0.2637227475643158, 'posdis_generic': 0.1532263606786728, 'bosdis_generic': 0.2642113268375397, 'posdis': 0.07538603991270065, 'bosdis': 0.26492154598236084}\n",
      "data set [8, 8, 8]\n",
      "{'posdis_specific': 0.04069240391254425, 'bosdis_specific': 0.1851859986782074, 'posdis_generic': 0.02718394435942173, 'bosdis_generic': 0.29024362564086914, 'posdis': 0.04009595513343811, 'bosdis': 0.18857862055301666}\n",
      "{'posdis_specific': 0.04350518807768822, 'bosdis_specific': 0.20536062121391296, 'posdis_generic': 0.020340433344244957, 'bosdis_generic': 0.2739049792289734, 'posdis': 0.030999163165688515, 'bosdis': 0.20685537159442902}\n",
      "{'posdis_specific': 0.04969507455825806, 'bosdis_specific': 0.12943284213542938, 'posdis_generic': 0.0333930104970932, 'bosdis_generic': 0.20779070258140564, 'posdis': 0.04839161038398743, 'bosdis': 0.13922536373138428}\n",
      "{'posdis_specific': 0.025246843695640564, 'bosdis_specific': 0.10552417486906052, 'posdis_generic': 0.032755717635154724, 'bosdis_generic': 0.2082243114709854, 'posdis': 0.021885579451918602, 'bosdis': 0.11873717606067657}\n",
      "{'posdis_specific': 0.05010226368904114, 'bosdis_specific': 0.20279161632061005, 'posdis_generic': 0.04462899640202522, 'bosdis_generic': 0.32045111060142517, 'posdis': 0.06121060252189636, 'bosdis': 0.21089687943458557}\n",
      "data set [4, 4, 4, 4]\n",
      "{'posdis_specific': 0.02617955580353737, 'bosdis_specific': 0.42350658774375916, 'posdis_generic': 0.04773803800344467, 'bosdis_generic': 0.233015775680542, 'posdis': 0.02747374027967453, 'bosdis': 0.4049025774002075}\n",
      "{'posdis_specific': 0.04328310117125511, 'bosdis_specific': 0.38225239515304565, 'posdis_generic': 0.023821106180548668, 'bosdis_generic': 0.1480262726545334, 'posdis': 0.037911027669906616, 'bosdis': 0.35238131880760193}\n",
      "{'posdis_specific': 0.03206302970647812, 'bosdis_specific': 0.29722878336906433, 'posdis_generic': 0.029602091759443283, 'bosdis_generic': 0.1925947368144989, 'posdis': 0.027937673032283783, 'bosdis': 0.28211909532546997}\n",
      "{'posdis_specific': 0.01554359681904316, 'bosdis_specific': 0.37755265831947327, 'posdis_generic': 0.038022730499506, 'bosdis_generic': 0.2453024983406067, 'posdis': 0.0209474079310894, 'bosdis': 0.3619994521141052}\n",
      "{'posdis_specific': 0.02464435249567032, 'bosdis_specific': 0.3407096564769745, 'posdis_generic': 0.056199122220277786, 'bosdis_generic': 0.23916660249233246, 'posdis': 0.02287883125245571, 'bosdis': 0.33810997009277344}\n"
     ]
    }
   ],
   "source": [
    "# use Disent callback from egg\n",
    "\n",
    "for d in range(len(datasets)): \n",
    "    \n",
    "    path = paths[d]\n",
    "    dim = [n_values[d]] * n_attributes[d]\n",
    "    n_features = n_attributes[d] * n_values[d]\n",
    "    vs_factor = int(path[-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    print(\"data set\", dim)\n",
    "    \n",
    "    for run in range(5):\n",
    "        \n",
    "        posdis_bosdis = {}\n",
    "    \n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        \n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        n_targets = int(sender_input.shape[1]/2)\n",
    "        # get target objects and fixed vectors to re-construct concepts\n",
    "        target_objects = sender_input[:, :n_targets]\n",
    "        target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "        # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "        (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "        # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "        objects = objects + 1\n",
    "        concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "        # concrete/specific concepts: where all attributes are fixed\n",
    "        concepts_specific = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]])\n",
    "        messages_specific = messages[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]]\n",
    "\n",
    "        # generic concepts: where only one attribute is fixed\n",
    "        concepts_generic = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == 1])\n",
    "        messages_generic = messages[torch.sum(torch.from_numpy(fixed), dim=1) == 1]\n",
    "        \n",
    "        posdis_specific = Disent.posdis(concepts_specific, messages_specific)\n",
    "        bosdis_specific = Disent.bosdis(concepts_specific, messages_specific, vocab_size)\n",
    "\n",
    "        posdis_generic = Disent.posdis(concepts_generic, messages_generic)\n",
    "        bosdis_generic = Disent.bosdis(concepts_generic, messages_generic, vocab_size)\n",
    "        \n",
    "        posdis = Disent.posdis(torch.from_numpy(objects), messages)\n",
    "        bosdis = Disent.bosdis(torch.from_numpy(objects), messages, vocab_size)\n",
    "        \n",
    "        posdis_bosdis['posdis_specific'] = posdis_specific\n",
    "        posdis_bosdis['bosdis_specific'] = bosdis_specific\n",
    "        posdis_bosdis['posdis_generic'] = posdis_generic\n",
    "        posdis_bosdis['bosdis_generic'] = bosdis_generic\n",
    "        posdis_bosdis['posdis'] = posdis\n",
    "        posdis_bosdis['bosdis'] = bosdis\n",
    "\n",
    "        print(posdis_bosdis)\n",
    "    \n",
    "        if pickle_data:\n",
    "            pickle.dump(posdis_bosdis, open(path_to_run + \"posdis_bosdis.pkl\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
